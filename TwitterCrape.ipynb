{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TwitterCrape.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/plooox/SentimentalAnalysis/blob/master/TwitterCrape.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYH-CMmmMKkS"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjJlk8YGuQ4a"
      },
      "source": [
        "!pip install pororo\n",
        "!pip install snscrape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1XWafDAuSIO"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime as dt\n",
        "import re\n",
        "import snscrape.modules.twitter as sntwitter\n",
        "import pickle\n",
        "import csv\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaVLRGgoxkOy"
      },
      "source": [
        "from pororo import Pororo\n",
        "sa = Pororo(task = \"sentiment\", model = \"brainbert.base.ko.nsmc\", lang = \"ko\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrNuPb9K3to3"
      },
      "source": [
        "query = \"문재인\"\n",
        "start = \"2021-01-01\"\n",
        "end = \"2021-07-11\"\n",
        "\n",
        "pos = 0\n",
        "neg = 0\n",
        "\n",
        "dateTimeList = []\n",
        "posNegList = []\n",
        "contentList = []\n",
        "tweetList = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRjthy8pHzRJ"
      },
      "source": [
        "params = query+\"lang:ko \"+\"since:\"+start+\" until:\"+end\n",
        "#df = pd.DataFrame(tweetList, columns=[\"Datetime\", \"Pos/Neg\",\"Content\"])\n",
        "\n",
        "csvRoute = \"/content/drive/MyDrive/Colab Notebooks/Tweet Data/\"+query+\".csv\"\n",
        "\n",
        "csvFile = open(csvRoute, \"a\", newline='', encoding=\"utf-8\")\n",
        "csvWrite = csv.writer(csvFile)\n",
        "csvWrite.writerow([\"Date\",\"Pos/Neg\",\"Tweet\"])\n",
        "csvFile.close()\n",
        "\n",
        "for i,tweet in enumerate(sntwitter.TwitterSearchScraper(params).get_items()):\n",
        "    tw_content = tweet.content\n",
        "    tw_date = tweet.date\n",
        "    tw_posNeg = -1\n",
        "\n",
        "    dateTimeList.append(tw_date)\n",
        "    contentList.append(tw_content)\n",
        "\n",
        "    if sa(tw_content) == \"Positive\":\n",
        "        pos += 1\n",
        "        tw_posNeg = 1\n",
        "    if sa(tw_content) == \"Negative\":\n",
        "        neg += 1\n",
        "        tw_posNeg = 0\n",
        "    \n",
        "    #posNegList.append(tw_posNeg)\n",
        "    #tweetList.append([tw_date, tw_posNeg, tw_content])\n",
        "    csvFile = open(csvRoute, \"a\", newline='', encoding=\"utf-8\")\n",
        "    csvWrite = csv.writer(csvFile)\n",
        "\n",
        "    csvWrite.writerow([tw_date, tw_posNeg, tw_content])\n",
        "    \n",
        "    if (i % 1000 == 0):\n",
        "        print(\"Now: \"+ str(i) + \" (\" + str(tw_date) + \")\")\n",
        "\n",
        "    csvFile.close()\n",
        "        \n",
        "\n",
        "print(pos)\n",
        "print(neg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Czib-QBb3FUi"
      },
      "source": [
        "pos = 0\n",
        "neg = 0\n",
        "\n",
        "dateTimeList = []\n",
        "posNegList = []\n",
        "contentList = []\n",
        "tweetList = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kmIKdjwvmVW"
      },
      "source": [
        "query = \"아이유\"\n",
        "\n",
        "\n",
        "params = query+\"lang:ko \"+\"since:2021-01-01\"+\" until:2021-08-06\"\n",
        "df = pd.DataFrame(tweetList, columns=[\"Datetime\", \"Pos/Neg\",\"Content\"])\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/Tweet Data/IU.pkl\",\"wb\") as file:\n",
        "    pickle.dump(df, file)\n",
        "\n",
        "for i,tweet in enumerate(sntwitter.TwitterSearchScraper(params).get_items()):\n",
        "    tw_content = tweet.content\n",
        "    tw_date = tweet.date\n",
        "    tw_posNeg = -1\n",
        "\n",
        "    dateTimeList.append(tw_date)\n",
        "    contentList.append(tw_content)\n",
        "\n",
        "    if sa(tw_content) == \"Positive\":\n",
        "        pos += 1\n",
        "        tw_posNeg = 1\n",
        "    if sa(tw_content) == \"Negative\":\n",
        "        neg += 1\n",
        "        tw_posNeg = 0\n",
        "    \n",
        "    #posNegList.append(tw_posNeg)\n",
        "    tweetList.append([tw_date, tw_posNeg, tw_content])\n",
        "    if (i % 50 == 0):\n",
        "        print(\"Back Up: \"+ str(i) + \" (\" + str(tw_date) + \")\")\n",
        "        df = pd.DataFrame(tweetList, columns=[\"Datetime\", \"Pos/Neg\",\"Content\"])\n",
        "        with open(\"/content/drive/MyDrive/Colab Notebooks/Tweet Data/IU.pkl\",\"wb\") as file:\n",
        "            pickle.dump(df, file)\n",
        "\n",
        "\n",
        "print(len(tweetList))\n",
        "print(pos)\n",
        "print(neg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6v0XP4mYNzND"
      },
      "source": [
        "df2 = pd.DataFrame({'num_legs': [2, 4, 8, 0],\n",
        "                   'num_wings': [2, 0, 0, 0],\n",
        "                   'num_specimen_seen': [10, 2, 1, 8]},\n",
        "                   index=['a', 'b', 'd', 'c']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26AO8pjWVD4G"
      },
      "source": [
        "with open(\"/content/drive/MyDrive/Colab Notebooks/Tweet Data/mydata.pkl\",\"wb\") as file:\n",
        "    pickle.dump(df2, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diMG7TZT69kf"
      },
      "source": [
        "from numpy.lib.npyio import load\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/Tweet Data/IU.pkl\",\"rb\") as file:\n",
        "    loadData = pickle.load(file)\n",
        "    print(loadData)\n",
        "    print(type(loadData))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5xd0QDEW-xf"
      },
      "source": [
        "with open (\"/content/drive/MyDrive/Colab Notebooks/Tweet Data/mydata.pkl\", \"rb\") as file:\n",
        "    loaded = pickle.load(file)\n",
        "    print(loaded)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}